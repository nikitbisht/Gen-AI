{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7791df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b352d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474eda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tool creation\n",
    "\n",
    "@tool\n",
    "def multiply(a:int,b:int)->int:\n",
    "    '''multiply two number'''\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5773cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(multiply.invoke({'a':3,'b':8}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e132aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id = 'Qwen/Qwen3-235B-A22B',\n",
    "    task = 'text-generation',\n",
    "    huggingfacehub_api_token=api_key\n",
    ")\n",
    "\n",
    "c_llm = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba6dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_llm_with_tools = c_llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01492ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatHuggingFace(llm=HuggingFaceEndpoint(repo_id='Qwen/Qwen3-235B-A22B', huggingfacehub_api_token='', stop_sequences=[], server_kwargs={}, model_kwargs={}, model='Qwen/Qwen3-235B-A22B', client=<InferenceClient(model='Qwen/Qwen3-235B-A22B', timeout=120)>, async_client=<InferenceClient(model='Qwen/Qwen3-235B-A22B', timeout=120)>, task='text-generation'), model_id='Qwen/Qwen3-235B-A22B', model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply two number', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "152c5924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked, \"how are you, and what you can do.\" Let me break this down.\\n\\nFirst, they\\'re asking about my well-being, which is a common greeting. Then, they want to know what I can do. Since I\\'m an AI, I should respond politely and explain my capabilities.\\n\\nLooking at the tools provided, there\\'s a multiply function. But the user\\'s question isn\\'t about multiplying numbers. Theyâ€™re asking about my functionality in general. So, I don\\'t need to use the tool here. My response should be a friendly message detailing what I can assist with, like answering questions, providing information, performing calculations, etc.\\n\\nI should make sure to acknowledge their greeting and list some examples of tasks I can handle. No function call required for this query.\\n</think>\\n\\nI\\'m functioning well, thank you! I can assist with various tasks like answering questions, providing information, performing calculations, and more. For example, I can help multiply numbers using the `multiply` tool if needed. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 217, 'prompt_tokens': 158, 'total_tokens': 375}, 'model_name': 'Qwen/Qwen3-235B-A22B', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--7f6f6a3a-dd24-46ce-a8f8-51c5340230a1-0', usage_metadata={'input_tokens': 158, 'output_tokens': 217, 'total_tokens': 375})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_llm_with_tools.invoke('how are you, and what you can do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73dc9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = HumanMessage('can you multiply 3 with 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ecf5c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1121bb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='can you multiply 3 with 10', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ad62e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = c_llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c3f9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "85bc7665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='can you multiply 3 with 10', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\":3,\"b\":10}', 'name': 'multiply', 'description': None}, 'id': '0', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 196, 'total_tokens': 224}, 'model_name': 'HuggingFaceH4/zephyr-7b-beta', 'system_fingerprint': '3.2.1-sha-4d28897', 'finish_reason': 'stop', 'logprobs': None}, id='run--09ba4396-b89c-4048-a1a3-7f885422fe16-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 10}, 'id': '0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 196, 'output_tokens': 28, 'total_tokens': 224})]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "053513eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 3, 'b': 10}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "11830643",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_result = multiply.invoke(result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19935d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(tool_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c63fd31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='can you multiply 3 with 10', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\":3,\"b\":10}', 'name': 'multiply', 'description': None}, 'id': '0', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 196, 'total_tokens': 224}, 'model_name': 'HuggingFaceH4/zephyr-7b-beta', 'system_fingerprint': '3.2.1-sha-4d28897', 'finish_reason': 'stop', 'logprobs': None}, id='run--09ba4396-b89c-4048-a1a3-7f885422fe16-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 10}, 'id': '0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 196, 'output_tokens': 28, 'total_tokens': 224}),\n",
       " ToolMessage(content='30', name='multiply', tool_call_id='0')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78cc22b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\":3,\"b\":10}', 'name': 'multiply', 'description': None}, 'id': '0', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 96, 'total_tokens': 126}, 'model_name': 'HuggingFaceH4/zephyr-7b-beta', 'system_fingerprint': '3.2.1-sha-4d28897', 'finish_reason': 'stop', 'logprobs': None}, id='run--d9678e82-f74a-4db7-a708-f0bc468d1a42-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 10}, 'id': '0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 96, 'output_tokens': 30, 'total_tokens': 126})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdae26d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
